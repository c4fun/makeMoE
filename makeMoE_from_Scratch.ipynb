{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AviSoori1x/makeMoE/blob/main/makeMoE_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8e9b80fc-12cf-41a9-a0de-354f678b412b",
          "showTitle": false,
          "title": ""
        },
        "id": "90vgVgmDkRJQ"
      },
      "source": [
        "### 从头开始的稀疏专家混合语言模型，灵感来自（并在很大程度上基于）Andrej Karpathy的makemore（[https://github.com/karpathy/makemore）](https://github.com/karpathy/makemore%EF%BC%89) :)\n",
        "\n",
        "这是一个从头开始的稀疏专家混合语言模型的实现。这个项目的灵感来自于Andrej Karpathy的项目'makemore'，并且从该实现中借用了大部分可重用的组件。和makemore一样，makeMoE也是一个自回归的字符级语言模型，但是使用了前面提到的稀疏专家混合架构。\n",
        "\n",
        "和makemore一样，pytorch是唯一的要求（所以希望这个从头开始的声明是合理的）。\n",
        "\n",
        "与makemore架构相比的重要变化\n",
        "\n",
        "- 使用稀疏专家混合代替孤立的前馈神经网络。\n",
        "- 实施Top-k门控和嘈杂的Top-k门控。\n",
        "- 初始化 - 这里使用了Kaiming He初始化，但这个笔记本的重点是可操作性，所以您可以替换为Xavier Glorot等，并进行尝试。\n",
        "\n",
        "与makemore相比未改变的部分\n",
        "\n",
        "- 数据集、预处理（标记化）以及Andrej最初选择的语言建模任务-生成类似莎士比亚文本\n",
        "- 因果自注意力实施\n",
        "- 训练循环\n",
        "- 推理逻辑\n",
        "\n",
        "在此实现中引用的出版物：\n",
        "\n",
        "- 专家混合：https://arxiv.org/pdf/2401.04088.pdf\n",
        "- 极大规模神经网络：稀疏门控专家混合层：https://arxiv.org/pdf/1701.06538.pdf\n",
        "\n",
        "本笔记本详细介绍了整个模型架构的直观理解以及所有内容的整合方式。\n",
        "\n",
        "代码是在Databricks上完全开发的，使用了一台A100进行计算。如果您在Databricks上运行此代码，可以在您选择的云提供商中轻松扩展到任意大的GPU集群中，没有任何问题。\n",
        "\n",
        "我选择使用mlflow（在Databricks上预安装。您可以在其他地方轻松安装pip）因为我发现它有助于跟踪和记录所有必要的指标。这完全是可选的。\n",
        "\n",
        "请注意，该实现强调可读性和可操作性而不是性能，因此有许多方法可以改进。请尝试并告诉我。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2f4a58a8-bd4c-40de-a4a9-95457842db0b",
          "showTitle": false,
          "title": ""
        },
        "id": "hywLNfb0kRJT"
      },
      "source": [
        "![mixture of experts overview](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/moe.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "35b3daa3-3b3b-47af-b3e7-be95878f9e06",
          "showTitle": false,
          "title": ""
        },
        "id": "RQAnP6_RkRJU"
      },
      "outputs": [],
      "source": [
        "#Using mlflow is entirely optional. I personally like to use MLFlow to track and log everything. If you're using Databricks, it comes pre-installed.\n",
        "%pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5e1a3e38-8717-42ec-9bbc-71d3712c1c68",
          "showTitle": false,
          "title": ""
        },
        "id": "V521QQ_qkRJV"
      },
      "outputs": [],
      "source": [
        "#Import the necessary packages and set seed for reproducibility. For this notebook, pytorch is all you need\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(42)\n",
        "#Optional\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "faf99ef2-39bb-46fc-b772-05d6d0482bbc",
          "showTitle": false,
          "title": ""
        },
        "id": "-4r_QNRRkRJV"
      },
      "source": [
        "Next few sections, downloading the data, preprocessing it and self attention are directly from makemore. I have elaborated a little on self attention and added visual aids to understand the process a bit better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45143d84-28c7-463d-9fb5-e21122842600",
          "showTitle": false,
          "title": ""
        },
        "id": "2GhDw0yWkRJV",
        "outputId": "22b79649-9819-4c65-a46a-d0796d6c9085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-29 16:50:31--  https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 0.0.0.0, ::\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|0.0.0.0|:443... failed: Connection refused.\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|::|:443... failed: Connection refused.\n"
          ]
        }
      ],
      "source": [
        "# Downloading the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "192e830a-762d-4573-9484-70a58deb1fec",
          "showTitle": false,
          "title": ""
        },
        "id": "3sPAL1AKkRJW"
      },
      "outputs": [],
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2d7181b7-f5e5-4ab5-bdd8-74c507c798ad",
          "showTitle": false,
          "title": ""
        },
        "id": "wNkF3RYLkRJX",
        "outputId": "671be677-be3d-49e0-d391-569559a99ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "68032e07-8625-4750-a340-bc8f4eed2458",
          "showTitle": false,
          "title": ""
        },
        "id": "AHIwr-yxkRJX",
        "outputId": "fa10ee0f-c8cb-4ba1-9fb1-79f9fbf336fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6995ad6-c9ac-4a21-9da0-ebbd3273c991",
          "showTitle": false,
          "title": ""
        },
        "id": "DHGayz7mkRJY",
        "outputId": "54b52e55-b6b9-4bdc-974a-5c48a43e1497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "43002fa3-ffd3-416c-9aaf-0a03b19c7bc1",
          "showTitle": false,
          "title": ""
        },
        "id": "pzn11WJckRJY",
        "outputId": "cd7b3ff1-680b-4036-b3c8-b597a361aeb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b4609fc4-09c7-4a39-8367-e9ee39d440ed",
          "showTitle": false,
          "title": ""
        },
        "id": "YbBGz0O2kRJY",
        "outputId": "49e94dde-6e1f-4a9e-a18b-9b8f1c51de86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "88f7cb0d-02ff-42b0-92a5-a505dc3f8f25",
          "showTitle": false,
          "title": ""
        },
        "id": "hoLIeA7YkRJZ"
      },
      "outputs": [],
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6b554ddf-50f4-441b-8acf-10b81a508b7e",
          "showTitle": false,
          "title": ""
        },
        "id": "VY55nr6EkRJZ",
        "outputId": "1a5685e9-66bb-40ed-f19a-f0cb09e8e51c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "22ba4512-309d-4895-a908-2ef3efa317bc",
          "showTitle": false,
          "title": ""
        },
        "id": "5YbgrB9HkRJZ",
        "outputId": "05577a5f-10d5-495b-82e8-c3278b4fdea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bf386bff-0f63-4358-82fc-6c7d02c37321",
          "showTitle": false,
          "title": ""
        },
        "id": "Oaxhage8kRJZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "99acd85c-233f-4f2d-a062-028dbcde9960",
          "showTitle": false,
          "title": ""
        },
        "id": "HfpkIUNdkRJZ",
        "outputId": "1ad2bc10-2b4a-458b-a6ee-a169728ec90d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([250930, 237205, 974116, 383898])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e46dc826-9f39-4aed-b2d2-f9ea401136de",
          "showTitle": false,
          "title": ""
        },
        "id": "faoGVPG3kRJa",
        "outputId": "dcf8b139-d8f8-4565-a962-62d094c5da9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[42,  1, 58, 46, 59, 57,  1, 21],\n",
              "        [54, 56, 47, 43, 57, 58, 11,  0],\n",
              "        [49, 47, 52, 45, 12,  1, 58, 46],\n",
              "        [58, 46, 53, 59, 58,  1, 56, 43]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2886aedf-200e-40bd-9a9d-4658cf6c509b",
          "showTitle": false,
          "title": ""
        },
        "id": "hkllYFCPkRJa",
        "outputId": "9350713c-be0f-492a-c873-bd279226668d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1, 58, 46, 59, 57,  1, 21,  1],\n",
              "        [56, 47, 43, 57, 58, 11,  0, 37],\n",
              "        [47, 52, 45, 12,  1, 58, 46, 53],\n",
              "        [46, 53, 59, 58,  1, 56, 43, 42]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a486fc04-ed29-456f-918b-5f8395e455cb",
          "showTitle": false,
          "title": ""
        },
        "id": "tWrajECBkRJa"
      },
      "source": [
        "下面的代码块清楚地展示了预测的自回归性质，以及上下文是在一个一维的令牌排列（在这种情况下是字符）上滚动的窗口。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "49a86e10-ac37-4b92-8f18-775cd4853fdc",
          "showTitle": false,
          "title": ""
        },
        "id": "xjgtxxztkRJa",
        "outputId": "1be0ebc2-b22d-4136-e77d-ecdafded66d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 6,  0, 14, 43, 44, 53, 56, 43],\n",
            "        [39,  1, 42, 59, 43,  1, 39, 52],\n",
            "        [47, 41, 43,  1, 39, 52, 42,  1],\n",
            "        [53, 44,  1, 50, 43, 58,  1, 58]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 0, 14, 43, 44, 53, 56, 43,  1],\n",
            "        [ 1, 42, 59, 43,  1, 39, 52, 42],\n",
            "        [41, 43,  1, 39, 52, 42,  1, 42],\n",
            "        [44,  1, 50, 43, 58,  1, 58, 46]])\n",
            "----\n",
            "when input is [6] the target: 0\n",
            "when input is [6, 0] the target: 14\n",
            "when input is [6, 0, 14] the target: 43\n",
            "when input is [6, 0, 14, 43] the target: 44\n",
            "when input is [6, 0, 14, 43, 44] the target: 53\n",
            "when input is [6, 0, 14, 43, 44, 53] the target: 56\n",
            "when input is [6, 0, 14, 43, 44, 53, 56] the target: 43\n",
            "when input is [6, 0, 14, 43, 44, 53, 56, 43] the target: 1\n",
            "when input is [39] the target: 1\n",
            "when input is [39, 1] the target: 42\n",
            "when input is [39, 1, 42] the target: 59\n",
            "when input is [39, 1, 42, 59] the target: 43\n",
            "when input is [39, 1, 42, 59, 43] the target: 1\n",
            "when input is [39, 1, 42, 59, 43, 1] the target: 39\n",
            "when input is [39, 1, 42, 59, 43, 1, 39] the target: 52\n",
            "when input is [39, 1, 42, 59, 43, 1, 39, 52] the target: 42\n",
            "when input is [47] the target: 41\n",
            "when input is [47, 41] the target: 43\n",
            "when input is [47, 41, 43] the target: 1\n",
            "when input is [47, 41, 43, 1] the target: 39\n",
            "when input is [47, 41, 43, 1, 39] the target: 52\n",
            "when input is [47, 41, 43, 1, 39, 52] the target: 42\n",
            "when input is [47, 41, 43, 1, 39, 52, 42] the target: 1\n",
            "when input is [47, 41, 43, 1, 39, 52, 42, 1] the target: 42\n",
            "when input is [53] the target: 44\n",
            "when input is [53, 44] the target: 1\n",
            "when input is [53, 44, 1] the target: 50\n",
            "when input is [53, 44, 1, 50] the target: 43\n",
            "when input is [53, 44, 1, 50, 43] the target: 58\n",
            "when input is [53, 44, 1, 50, 43, 58] the target: 1\n",
            "when input is [53, 44, 1, 50, 43, 58, 1] the target: 58\n",
            "when input is [53, 44, 1, 50, 43, 58, 1, 58] the target: 46\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "dde3273f-0519-4108-ba84-dfd99e020722",
          "showTitle": false,
          "title": ""
        },
        "id": "RlON_gNikRJa"
      },
      "source": [
        "### 理解因果缩放点积自注意力的直觉\n",
        "\n",
        "此代码来自于Andrej Karpathy的优秀makemore存储库，链接在仓库中"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e435d0cf-1383-446a-9026-cd80b4266019",
          "showTitle": false,
          "title": ""
        },
        "id": "uBVWP40SkRJa"
      },
      "source": [
        "![scaled dot product self attention](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/self_attention.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "97660589-1719-48c0-ad6f-4f7c2888348a",
          "showTitle": false,
          "title": ""
        },
        "id": "i-jFgMntkRJa"
      },
      "source": [
        "提供的代码演示了自注意力机制和基本概念，特别关注经典的缩放点积自注意力。在这个变体中，查询、键和值矩阵都来自同一个输入序列。为了确保自回归语言生成过程的完整性，特别是在仅有解码器的模型中，代码实现了掩码。这种掩码技术至关重要，因为它隐藏了当前标记位置之后的任何信息，从而将模型的注意力集中在序列之前的部分。这样的注意机制被称为因果自注意力。值得注意的是，稀疏专家混合模型不仅限于仅有解码器的Transformer架构。实际上，这个领域的许多重要工作，特别是Shazeer等人的工作，都围绕着T5架构展开，该架构包含了Transformer模型中的编码器和解码器组件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6f82ca41-a301-4a92-aed9-ba7ac3a2bf88",
          "showTitle": false,
          "title": ""
        },
        "id": "lxMSgZWGkRJb",
        "outputId": "8d968403-a14f-4f3c-f2ce-9099a2b34f1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1) #B,T,T\n",
        "\n",
        "v = value(x) #B,T,H\n",
        "out = wei @ v # (B,T,T) @ (B,T,H) -> (B,T,H)\n",
        "#The output from this final matrix product is subsequently passsed through a linear layer as shown in the diagram above\n",
        "\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "49c278ec-19db-4c5d-b4a3-3bdc45c5a443",
          "showTitle": false,
          "title": ""
        },
        "id": "cA3iXggEkRJb"
      },
      "source": [
        "将代码进行泛化和模块化，用于因果自注意力和多头因果自注意力。多头自注意力并行应用多个注意力头，每个头都专注于通道的不同部分（嵌入维度）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "608c6c9f-fb93-43ed-9580-5e782fd90d61",
          "showTitle": false,
          "title": ""
        },
        "id": "909nX3PHkRJb"
      },
      "outputs": [],
      "source": [
        "#Causal scaled dot product self-Attention Head\n",
        "\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "head_size = 16\n",
        "dropout = 0.1\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6e8b31af-f45a-4066-8288-fb0d9c8e2aff",
          "showTitle": false,
          "title": ""
        },
        "id": "T3MoVK_WkRJb"
      },
      "outputs": [],
      "source": [
        "#Multi-Headed Self Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "16267e9a-008b-46e3-82ce-2ae41396a1a1",
          "showTitle": false,
          "title": ""
        },
        "id": "T-w53_mSkRJb",
        "outputId": "052e4478-b284-43c7-924c-fcf13deea320"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 64])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Confirming that what's output from multi head attention is the original embedding size\n",
        "B,T,C = 4,8,64 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "mha = MultiHeadAttention(4,16)\n",
        "mha(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5f7ff128-7fe5-4a91-b9f2-208e2132e505",
          "showTitle": false,
          "title": ""
        },
        "id": "wNlJTtfhkRJb"
      },
      "source": [
        "### 创建专家模块 比如一个简单的MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f6e422a5-57c1-4b2f-b7b9-2757e109848a",
          "showTitle": false,
          "title": ""
        },
        "id": "zv3fGRpbkRJb"
      },
      "source": [
        "在稀疏的专家混合（MoE）架构中，每个Transformer块中的自注意机制保持不变。然而，在每个块的结构中发生了一个显著的改变：标准的前馈神经网络被几个稀疏激活的前馈网络（称为专家）所取代。所谓\"稀疏激活\"是指将序列中的每个标记仅路由到有限数量的专家中，通常是可用总数的一到两个。这种修改允许对输入数据的不同部分进行专门处理，使模型能够高效地处理更广泛的复杂性。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "efe9fdcc-82eb-4047-9233-ad3cfe8759b1",
          "showTitle": false,
          "title": ""
        },
        "id": "7Kz0Y_P0kRJc"
      },
      "source": [
        "![experts](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/experts.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a2f0f382-ab4a-45e1-9dce-27ae0d3da641",
          "showTitle": false,
          "title": ""
        },
        "id": "a-9CYWXgkRJc"
      },
      "outputs": [],
      "source": [
        "#Expert module\n",
        "class Expert(nn.Module):\n",
        "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a7764385-26e9-4d75-9aa7-ce011023e24e",
          "showTitle": false,
          "title": ""
        },
        "id": "qderdEuykRJc"
      },
      "source": [
        "通过示例理解 Top-k 门控机制直觉"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d3fca4df-4c47-4e9a-98cd-08cf8ccf7726",
          "showTitle": false,
          "title": ""
        },
        "id": "VxJv5y44kRJc"
      },
      "source": [
        "![top k gating](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/topk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8e494b86-cdb2-4f2a-8824-5fa2ef4b2606",
          "showTitle": false,
          "title": ""
        },
        "id": "n6DuhY0DkRJc"
      },
      "source": [
        "门控网络，也称为路由器，确定每个令牌从多头注意力中发送到哪个专家网络。让我们考虑一个简单的例子：假设有4个专家，并且将令牌路由到前2个专家。首先，我们通过线性层将令牌输入到门控网络中。该层将输入张量从形状（2，4，32）——表示（批量大小，令牌，n_embed，其中n_embed是输入的通道维度）——投射到新形状（2，4，4），对应于（批量大小，令牌，num_experts），其中num_experts是专家网络的数量。在此之后，我们确定最高的k=2个值及其在最后一个维度上的索引。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "621916ff-2290-4e2f-9fd7-5181ed98d540",
          "showTitle": false,
          "title": ""
        },
        "id": "pNAuFDDvkRJc",
        "outputId": "a9d313d5-1dd1-4df8-9c9a-dc6d0b90d4ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 0.9558,  0.1610],\n",
              "          [ 0.8659, -0.1494],\n",
              "          [ 0.8765,  0.7202],\n",
              "          [ 0.9496, -0.6609]],\n",
              " \n",
              "         [[ 0.4419, -0.2500],\n",
              "          [ 1.2602,  0.8430],\n",
              "          [ 0.8570,  0.7822],\n",
              "          [ 0.7376,  0.2561]]], grad_fn=<TopkBackward0>),\n",
              " tensor([[[2, 0],\n",
              "          [3, 2],\n",
              "          [3, 0],\n",
              "          [1, 2]],\n",
              " \n",
              "         [[1, 3],\n",
              "          [1, 2],\n",
              "          [1, 2],\n",
              "          [0, 1]]]))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Understanding how gating works\n",
        "num_experts = 4\n",
        "top_k=2\n",
        "n_embed=32\n",
        "\n",
        "\n",
        "#Example multi-head attention output for a simple illustrative example, consider n_embed=32, context_length=4 and batch_size=2\n",
        "mh_output = torch.randn(2, 4, n_embed)\n",
        "\n",
        "topkgate_linear = nn.Linear(n_embed, num_experts) # nn.Linear(32, 4)\n",
        "\n",
        "logits = topkgate_linear(mh_output)\n",
        "top_k_logits, top_k_indices = logits.topk(top_k, dim=-1)  # Get top-k experts\n",
        "top_k_logits, top_k_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0f135ff7-0aa3-4b6d-ab5e-42399c48427b",
          "showTitle": false,
          "title": ""
        },
        "id": "EKwAyJxrkRJd"
      },
      "source": [
        "获取稀疏门控输出，只保留各自索引上最大的 k 个值。用“-inf”填充其余部分，并通过softmax激活函数。这样可以将“-inf”值推向零，使得前两个值更加突出且总和为1。这种总和为1的效果有助于对专家输出进行加权。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "735e160a-ef1e-424d-b6d9-09f63ea99ec1",
          "showTitle": false,
          "title": ""
        },
        "id": "IiVejzOpkRJd",
        "outputId": "2ff61217-56f8-4835-d310-2169240fb4a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1610,    -inf,  0.9558,    -inf],\n",
              "         [   -inf,    -inf, -0.1494,  0.8659],\n",
              "         [ 0.7202,    -inf,    -inf,  0.8765],\n",
              "         [   -inf,  0.9496, -0.6609,    -inf]],\n",
              "\n",
              "        [[   -inf,  0.4419,    -inf, -0.2500],\n",
              "         [   -inf,  1.2602,  0.8430,    -inf],\n",
              "         [   -inf,  0.8570,  0.7822,    -inf],\n",
              "         [ 0.7376,  0.2561,    -inf,    -inf]]], grad_fn=<ScatterBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros = torch.full_like(logits, float('-inf')) #full_like clones a tensor and fills it with a specified value (like infinity) for masking or calculations.\n",
        "sparse_logits = zeros.scatter(-1, top_k_indices, top_k_logits)\n",
        "sparse_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9146e6f9-4eee-4a8b-8338-55072719ed59",
          "showTitle": false,
          "title": ""
        },
        "id": "HFgRxDF4kRJh",
        "outputId": "cde71bbf-ba67-4972-eef1-2fba48a106d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.3111, 0.0000, 0.6889, 0.0000],\n",
              "         [0.0000, 0.0000, 0.2660, 0.7340],\n",
              "         [0.4610, 0.0000, 0.0000, 0.5390],\n",
              "         [0.0000, 0.8335, 0.1665, 0.0000]],\n",
              "\n",
              "        [[0.0000, 0.6664, 0.0000, 0.3336],\n",
              "         [0.0000, 0.6028, 0.3972, 0.0000],\n",
              "         [0.0000, 0.5187, 0.4813, 0.0000],\n",
              "         [0.6181, 0.3819, 0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gating_output= F.softmax(sparse_logits, dim=-1)\n",
        "gating_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "fe558b12-e443-4b62-9a85-c59120456352",
          "showTitle": false,
          "title": ""
        },
        "id": "dGJrq2uqkRJh"
      },
      "source": [
        "### 将上述代码泛化和模块化，并添加嘈杂的前k个门控以实现负载均衡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45516b59-d814-4853-a34e-d36aae9f04eb",
          "showTitle": false,
          "title": ""
        },
        "id": "TKp4DqwYkRJh"
      },
      "outputs": [],
      "source": [
        "# First define the top k router module\n",
        "class TopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(TopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        self.linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "    def forward(self, mh_ouput):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.linear(mh_output)\n",
        "        top_k_logits, indices = logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c500844f-0866-4bbf-acef-c0c1d4979721",
          "showTitle": false,
          "title": ""
        },
        "id": "KjkouzwkkRJh",
        "outputId": "4e5cd861-4f75-4e98-c3cf-5697fb5f7451"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 4, 4]),\n",
              " tensor([[[0.0000, 0.4249, 0.5751, 0.0000],\n",
              "          [0.3467, 0.6533, 0.0000, 0.0000],\n",
              "          [0.3970, 0.0000, 0.6030, 0.0000],\n",
              "          [0.0000, 0.0000, 0.7713, 0.2287]],\n",
              " \n",
              "         [[0.4043, 0.5957, 0.0000, 0.0000],\n",
              "          [0.0000, 0.5281, 0.0000, 0.4719],\n",
              "          [0.7053, 0.0000, 0.2947, 0.0000],\n",
              "          [0.0000, 0.4602, 0.5398, 0.0000]]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[[2, 1],\n",
              "          [1, 0],\n",
              "          [2, 0],\n",
              "          [2, 3]],\n",
              " \n",
              "         [[1, 0],\n",
              "          [1, 3],\n",
              "          [0, 2],\n",
              "          [2, 1]]]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Testing this out:\n",
        "num_experts = 4\n",
        "top_k = 2\n",
        "n_embd = 32\n",
        "\n",
        "mh_output = torch.randn(2, 4, n_embd)  # Example input\n",
        "top_k_gate = TopkRouter(n_embd, num_experts, top_k)\n",
        "gating_output, indices = top_k_gate(mh_output)\n",
        "gating_output.shape, gating_output, indices\n",
        "#And it works!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9fa02d0c-3688-4d01-811d-d0b2b851ab33",
          "showTitle": false,
          "title": ""
        },
        "id": "tAouN-GwkRJi"
      },
      "source": [
        "虽然最近发布的mixture paper没有提到，我认为嘈杂的前k个门是训练MoE模型的重要工具。基本上，您不希望所有令牌都发送到同一组“喜爱的”专家。您希望在开发和探索之间保持良好的平衡。为了负载平衡，有助于将标准正态噪声添加到门控线性层的对数中。这样可以使训练更加高效。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e05b3306-b89f-4ebc-901b-f16398a925c2",
          "showTitle": false,
          "title": ""
        },
        "id": "aWeueE83kRJi"
      },
      "source": [
        "![noisy top-k gating](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/noisytopkgating.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dda4d805-373c-48f7-9037-da08fbc06e64",
          "showTitle": false,
          "title": ""
        },
        "id": "ZBrN-w3JkRJi"
      },
      "outputs": [],
      "source": [
        "#Changing the above to accomodate noisy top-k gating\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        #layer for router logits\n",
        "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
        "        self.noise_linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "\n",
        "        #Noise logits\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "\n",
        "        #Adding scaled unit gaussian noise to the logits\n",
        "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "        noisy_logits = logits + noise\n",
        "\n",
        "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a01a9d6b-fedb-427d-b0da-c3b2a75a8643",
          "showTitle": false,
          "title": ""
        },
        "id": "7Q6KcH9AkRJi",
        "outputId": "7aea5328-ba96-4c98-b550-042ecf440700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 4, 8]),\n",
              " tensor([[[0.0000, 0.4304, 0.0000, 0.5696, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.4109, 0.0000, 0.0000, 0.0000, 0.5891],\n",
              "          [0.0000, 0.3708, 0.0000, 0.0000, 0.0000, 0.0000, 0.6292, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.4542, 0.0000, 0.5458, 0.0000]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.1747, 0.0000, 0.0000, 0.0000, 0.8253, 0.0000],\n",
              "          [0.0000, 0.0000, 0.5008, 0.4992, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.6160, 0.0000, 0.3840, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1952, 0.0000, 0.8048]]],\n",
              "        grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[[3, 1],\n",
              "          [7, 3],\n",
              "          [6, 1],\n",
              "          [6, 4]],\n",
              " \n",
              "         [[6, 2],\n",
              "          [2, 3],\n",
              "          [4, 6],\n",
              "          [7, 5]]]))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Testing this out, again:\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "n_embd = 16\n",
        "\n",
        "mh_output = torch.randn(2, 4, n_embd)  # Example input\n",
        "noisy_top_k_gate = NoisyTopkRouter(n_embd, num_experts, top_k)\n",
        "gating_output, indices = noisy_top_k_gate(mh_output)\n",
        "gating_output.shape, gating_output, indices\n",
        "#It works!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "076fa004-a165-42a7-b729-0bca8ad39418",
          "showTitle": false,
          "title": ""
        },
        "id": "XyKjpR-dkRJi"
      },
      "source": [
        "\n",
        "### 创建一个稀疏的 MoE 模块\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6747b8de-0086-4cb0-8fbd-46ee95457eb9",
          "showTitle": false,
          "title": ""
        },
        "id": "UsRCy7i3kRJi"
      },
      "source": [
        "这个过程的主要方面涉及到门控网络的输出。在获取这些结果后，将前k个值选择性地与相应的前k个专家的输出相乘，形成加权和，这构成了SparseMoe块的输出。这个过程的关键和具有挑战性的部分是避免不必要的乘法。只对top_k的专家进行前向传递，并计算这个加权和是非常重要的。对每个专家都进行前向传递将违背使用稀疏MoE的目的，因为它将不再是稀疏的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d6809b3f-4be9-4859-b39e-24fcdd6c8d86",
          "showTitle": false,
          "title": ""
        },
        "id": "7dDUHU_IkRJi"
      },
      "outputs": [],
      "source": [
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def forward(self, x):\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # Reshape inputs for batch processing\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        # Process each expert in parallel\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            # Create a mask for the inputs where the current expert is in top-k\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                expert_output = expert(expert_input)\n",
        "\n",
        "                # Extract and apply gating scores\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                # Update final output\n",
        "                # We need to scatter_add the weighted outputs to their original positions in the batch\n",
        "                final_output.masked_scatter_(expert_mask.unsqueeze(-1), weighted_output)\n",
        "\n",
        "        return final_output.view_as(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "06239630-0a1c-47c9-976c-7770f3d82e18",
          "showTitle": false,
          "title": ""
        },
        "id": "q8kDLI1ukRJj",
        "outputId": "69e7b330-cd47-4094-99c2-7928f8b60d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the final output: torch.Size([4, 8, 16])\n",
            "tensor([[[ 6.1727e-02, -1.1298e-01, -4.1579e-02, -2.8002e-03,  0.0000e+00,\n",
            "           7.7357e-02,  3.6960e-02, -1.0697e-01,  1.2526e-02,  1.0065e-02,\n",
            "           2.5494e-02,  5.7258e-02,  3.1733e-02, -1.2904e-01,  3.1911e-02,\n",
            "          -9.2942e-02],\n",
            "         [-2.6267e-02, -2.1804e-01,  0.0000e+00,  0.0000e+00,  2.9232e-01,\n",
            "           2.2580e-01,  0.0000e+00, -2.6606e-01, -6.0905e-02, -6.9949e-03,\n",
            "           1.9965e-01,  2.1709e-01, -1.2841e-01, -2.2774e-01,  9.0908e-02,\n",
            "          -0.0000e+00],\n",
            "         [-9.4502e-02, -3.3213e-01,  4.8503e-02,  2.1059e-02,  2.4934e-01,\n",
            "           6.4678e-02, -9.2514e-02, -7.5233e-02,  1.4475e-01,  0.0000e+00,\n",
            "          -5.1047e-02, -7.9036e-02,  4.8226e-02, -0.0000e+00, -1.0702e-01,\n",
            "           2.8969e-03],\n",
            "         [ 1.3531e-01, -2.6609e-02,  0.0000e+00,  2.2722e-01, -1.2779e-01,\n",
            "           3.2449e-02,  2.2538e-03, -6.9114e-02,  9.8225e-02, -8.9362e-02,\n",
            "           1.6459e-01,  1.1035e-01,  7.0970e-02, -2.5286e-01,  7.3624e-02,\n",
            "           3.3992e-02],\n",
            "         [ 2.3093e-02, -1.6634e-01,  1.3268e-01, -3.7955e-02,  0.0000e+00,\n",
            "           5.8076e-02, -2.8576e-01, -3.8680e-01,  2.9840e-01, -7.4842e-02,\n",
            "           0.0000e+00,  1.4650e-01, -2.5771e-01,  8.3264e-02,  2.7305e-01,\n",
            "          -3.3373e-01],\n",
            "         [-5.5540e-02, -1.0644e-01,  9.2521e-02, -8.3701e-03,  3.3946e-02,\n",
            "           6.7005e-02,  1.3334e-01, -2.6413e-01,  5.5404e-02, -3.2691e-02,\n",
            "          -6.4163e-02,  8.9473e-02,  2.4871e-03, -9.4274e-02,  0.0000e+00,\n",
            "          -9.0755e-02],\n",
            "         [-1.5643e-01, -1.0924e-01,  5.8004e-02, -8.1961e-02,  9.0717e-02,\n",
            "           2.1321e-02,  1.6205e-01, -2.0858e-01, -8.1745e-02, -6.7670e-03,\n",
            "          -9.1852e-02,  1.1013e-01,  6.3894e-02,  0.0000e+00,  1.1903e-01,\n",
            "           2.8461e-02],\n",
            "         [ 1.9714e-01, -1.7787e-01, -8.0113e-03, -0.0000e+00,  1.1284e-01,\n",
            "           1.1682e-01, -1.6858e-01, -1.6523e-01,  9.9874e-02,  1.0447e-02,\n",
            "           0.0000e+00, -4.8994e-02, -7.2435e-02, -1.4833e-01,  1.3172e-01,\n",
            "          -0.0000e+00]],\n",
            "\n",
            "        [[ 6.0492e-02, -3.7522e-01,  3.7519e-02,  3.4758e-01, -0.0000e+00,\n",
            "          -8.1673e-02,  1.6996e-01, -1.2347e-01,  1.2231e-01,  4.6503e-02,\n",
            "          -2.1363e-01,  1.5122e-01,  1.0582e-01, -1.9945e-01,  1.2250e-01,\n",
            "           8.4910e-02],\n",
            "         [ 3.8122e-01,  1.8659e-01, -3.6525e-01, -1.8369e-01, -1.5873e-01,\n",
            "          -3.5122e-01,  2.1092e-01,  3.2503e-01,  2.7202e-01,  5.1146e-01,\n",
            "          -1.8837e-01,  1.2664e-01, -5.4119e-01, -1.0808e-01,  2.9885e-01,\n",
            "           2.6700e-01],\n",
            "         [ 0.0000e+00, -4.8438e-02, -4.6959e-02,  3.4773e-02,  1.4037e-01,\n",
            "          -1.6253e-01, -1.7464e-02, -5.6658e-02, -5.7714e-02,  5.1319e-02,\n",
            "           2.8324e-02, -1.1714e-01,  3.2928e-02,  1.9608e-02,  4.6926e-02,\n",
            "          -1.3237e-01],\n",
            "         [ 1.8322e-01, -4.5841e-02,  1.3811e-01, -7.8621e-02, -2.7854e-02,\n",
            "          -0.0000e+00, -6.3355e-02, -1.0999e-01,  2.2661e-01,  7.0362e-03,\n",
            "          -5.4486e-02, -7.8047e-02,  5.8757e-02,  1.8977e-01,  0.0000e+00,\n",
            "          -1.1398e-01],\n",
            "         [ 2.6847e-01,  1.6882e-01, -1.2736e-01,  8.4343e-02, -2.8952e-01,\n",
            "           1.2636e-01, -1.3666e-01, -3.7900e-01,  2.5832e-01, -1.8161e-01,\n",
            "           3.8750e-02,  0.0000e+00, -2.3959e-01, -1.2203e-01, -1.8529e-02,\n",
            "          -2.2042e-01],\n",
            "         [-1.6425e-01,  7.1375e-02,  4.7564e-02,  1.2458e-01, -7.7593e-02,\n",
            "           0.0000e+00,  2.4707e-02, -1.2113e-01, -1.1380e-01, -7.9187e-02,\n",
            "          -7.4101e-02,  4.4952e-02, -3.2598e-02, -1.7394e-01, -2.2042e-01,\n",
            "          -5.0890e-02],\n",
            "         [-0.0000e+00, -0.0000e+00,  2.6136e-02,  1.2570e-01,  2.1911e-01,\n",
            "           1.5705e-01, -1.6143e-01, -3.1784e-01,  0.0000e+00, -3.5266e-02,\n",
            "          -1.3237e-01,  3.3679e-01, -2.0042e-01,  1.3785e-01,  3.9561e-01,\n",
            "          -1.5747e-01],\n",
            "         [-1.1279e-01, -1.5219e-01,  9.7801e-02,  4.0813e-02,  2.8426e-02,\n",
            "           5.7654e-02, -4.3734e-02, -6.2298e-02, -6.5968e-02, -1.2167e-01,\n",
            "          -0.0000e+00,  6.4849e-02,  8.1602e-02, -0.0000e+00,  1.1272e-01,\n",
            "           1.3997e-02]],\n",
            "\n",
            "        [[ 1.9909e-01, -5.4632e-02, -1.4232e-01,  6.1973e-02,  5.8835e-02,\n",
            "          -5.9725e-02, -1.1966e-02,  7.0928e-02,  1.4189e-02,  1.7160e-01,\n",
            "          -3.9293e-02,  2.3533e-01, -4.8959e-02, -8.9088e-02,  1.3334e-01,\n",
            "           0.0000e+00],\n",
            "         [ 4.2767e-01,  2.7467e-01,  1.1543e-01,  1.0651e-01, -3.1467e-01,\n",
            "          -1.7216e-01,  5.8124e-02, -4.9138e-02,  0.0000e+00, -2.5793e-01,\n",
            "          -7.2218e-02,  7.3251e-02,  1.7469e-01, -3.5495e-01,  2.6203e-01,\n",
            "          -1.0456e-01],\n",
            "         [ 7.3780e-02, -1.8110e-01,  1.1546e-01,  0.0000e+00,  8.7258e-02,\n",
            "           7.0264e-02,  5.7631e-02, -8.8231e-02,  0.0000e+00,  6.0426e-02,\n",
            "          -0.0000e+00, -8.3655e-03,  1.1609e-02, -8.8824e-02,  0.0000e+00,\n",
            "           1.8684e-02],\n",
            "         [ 2.2075e-01, -9.0875e-02, -8.1975e-02, -4.4590e-01,  1.2736e-01,\n",
            "          -3.8408e-01,  1.6883e-01, -8.1663e-02, -2.6414e-01, -1.1203e-02,\n",
            "          -6.6625e-02,  1.4614e-01, -2.6727e-01,  1.0728e-01, -1.5723e-01,\n",
            "          -1.0395e-01],\n",
            "         [ 3.2236e-01, -4.8543e-02,  0.0000e+00,  1.1211e-01, -0.0000e+00,\n",
            "           3.0373e-01, -2.0155e-01, -3.6753e-01,  0.0000e+00, -2.7637e-01,\n",
            "           2.8463e-02,  1.8800e-01, -1.8429e-01, -1.4010e-02,  3.2368e-02,\n",
            "          -3.1250e-02],\n",
            "         [ 5.5584e-02, -1.9622e-01,  1.6490e-01,  1.6134e-01,  1.4218e-01,\n",
            "           1.8202e-01,  1.5735e-01, -3.6390e-01,  4.0004e-01,  1.8040e-01,\n",
            "           0.0000e+00,  9.4588e-02, -0.0000e+00, -1.2893e-01,  0.0000e+00,\n",
            "          -2.1900e-01],\n",
            "         [ 1.3247e-01,  4.7056e-02, -5.9244e-02,  1.5523e-01, -1.5450e-01,\n",
            "           3.1071e-02, -4.1701e-02, -1.4273e-01,  0.0000e+00, -3.8381e-02,\n",
            "           2.2025e-02,  0.0000e+00,  1.2512e-01, -1.8569e-01, -1.7355e-02,\n",
            "          -2.0517e-01],\n",
            "         [ 6.1876e-03, -4.8337e-04, -1.3895e-02,  4.5648e-04,  6.9341e-02,\n",
            "          -3.0030e-02, -4.4299e-03,  0.0000e+00, -8.0032e-03, -1.3502e-02,\n",
            "          -5.4373e-02, -5.9949e-02, -1.7037e-02, -3.1270e-02,  0.0000e+00,\n",
            "           6.7240e-03]],\n",
            "\n",
            "        [[ 1.2959e-01, -1.2541e-02,  2.7352e-01,  1.0319e-01,  3.4183e-02,\n",
            "           1.4690e-01, -1.5753e-02, -0.0000e+00,  4.2970e-02,  2.0017e-02,\n",
            "           2.6292e-01, -5.6960e-02, -9.7878e-02,  1.7441e-02,  1.7064e-01,\n",
            "          -3.0773e-02],\n",
            "         [-2.0723e-03, -1.8928e-01,  2.8115e-02,  6.3876e-02, -1.8837e-02,\n",
            "           9.6531e-02,  8.4911e-02, -1.4311e-01,  7.8583e-02,  5.2936e-03,\n",
            "          -1.5147e-01,  3.4100e-02,  1.8769e-01, -8.0730e-02,  5.1632e-02,\n",
            "           1.5155e-02],\n",
            "         [ 5.6422e-02, -3.7680e-02,  1.6322e-02, -5.6848e-02, -1.1438e-02,\n",
            "          -9.8330e-02, -6.7698e-02,  5.5775e-02, -1.6767e-01, -2.1067e-02,\n",
            "           1.1903e-01, -4.2821e-02, -8.2958e-02, -5.2251e-02, -4.2243e-02,\n",
            "           2.0221e-02],\n",
            "         [ 1.1304e-01, -1.4280e-01, -1.6565e-02, -4.5399e-01,  8.9314e-02,\n",
            "          -2.4449e-01,  1.1644e-01,  1.4552e-02, -2.8777e-01,  0.0000e+00,\n",
            "           5.6823e-02,  2.0142e-02, -2.7195e-01, -2.6189e-02,  6.0583e-02,\n",
            "          -4.9517e-02],\n",
            "         [-7.6577e-02, -3.9720e-02, -2.2520e-02,  1.0873e-01,  4.3109e-02,\n",
            "           0.0000e+00,  4.7761e-03, -2.8717e-01,  2.3731e-01, -3.0243e-02,\n",
            "           7.0338e-02,  0.0000e+00, -1.9702e-01, -5.6139e-02,  3.6643e-01,\n",
            "          -2.0759e-01],\n",
            "         [ 1.8061e-01, -1.6184e-01,  7.3507e-02, -2.4058e-01,  1.7651e-01,\n",
            "           0.0000e+00,  4.4814e-02, -1.7293e-01,  8.4796e-02, -2.1808e-01,\n",
            "           2.7839e-01,  1.2503e-01,  4.9513e-02, -2.0789e-01, -2.3729e-01,\n",
            "          -1.9982e-01],\n",
            "         [ 2.4804e-01, -1.4328e-01, -1.5655e-01, -2.3366e-01,  6.7683e-02,\n",
            "          -2.4412e-01,  2.8363e-02,  6.0197e-02, -2.8017e-01,  2.1936e-02,\n",
            "          -1.0630e-01, -1.4266e-01, -1.4755e-01,  2.1167e-01, -3.1427e-02,\n",
            "          -5.1615e-02],\n",
            "         [ 0.0000e+00, -0.0000e+00, -1.3070e-01,  3.1359e-02, -5.5229e-02,\n",
            "          -2.0509e-01, -0.0000e+00,  1.1720e-02,  2.4307e-03,  1.2226e-01,\n",
            "          -3.0287e-02,  6.5225e-02, -1.9175e-01, -2.9577e-03,  1.0795e-02,\n",
            "           1.4123e-01]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Let's test this out\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "n_embd = 16\n",
        "dropout=0.1\n",
        "\n",
        "mh_output = torch.randn(4, 8, n_embd)  # Example multi-head attention output\n",
        "sparse_moe = SparseMoE(n_embd, num_experts, top_k)\n",
        "final_output = sparse_moe(mh_output)\n",
        "print(\"Shape of the final output:\", final_output.shape)\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7476ca07-a315-4108-aa77-46173a703ca2",
          "showTitle": false,
          "title": ""
        },
        "id": "l7GoxCi2kRJj"
      },
      "source": [
        "强调一下，重要的是要认识到从路由器/门控网络输出的前k个专家的幅度，如上面的代码所示，也是很重要的。这些前k个索引标识了被激活的专家，并且这些前k个维度中的值的大小确定了它们各自的权重。这种加权求和的概念在下面的图表中进一步强调。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d99b5dce-301e-4380-8263-b5cfb4136ab2",
          "showTitle": false,
          "title": ""
        },
        "id": "e9a_oQ2akRJj"
      },
      "source": [
        "![sparse MoE](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/sparseMoEfinal.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "da5f3be4-f155-4d6c-bcbd-2f88a088261f",
          "showTitle": false,
          "title": ""
        },
        "id": "vMZCda7dkRJj"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0eaf71cd-c77e-40c7-b5be-e364e91685cf",
          "showTitle": false,
          "title": ""
        },
        "id": "f8yczkFHkRJj"
      },
      "outputs": [],
      "source": [
        "#First defining hyperparameters and boiler plate code. Imports and data preparation code is repeated for convenience\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 400\n",
        "head_size = 16\n",
        "n_embed = 128\n",
        "n_head = 8\n",
        "n_layer = 8\n",
        "dropout = 0.1\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ee1180f7-5004-4425-87fe-9a81a17b9024",
          "showTitle": false,
          "title": ""
        },
        "id": "QfxJ6B2fkRJj"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "#Multi-Headed Self Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embed, n_embed)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "03611a92-aaa2-4e0d-9755-cba56f96c794",
          "showTitle": false,
          "title": ""
        },
        "id": "y35jVCZYkRJk"
      },
      "outputs": [],
      "source": [
        "#Expert module\n",
        "class Expert(nn.Module):\n",
        "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "#noisy top-k gating\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        #layer for router logits\n",
        "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
        "        self.noise_linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "\n",
        "        #Noise logits\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "\n",
        "        #Adding scaled unit gaussian noise to the logits\n",
        "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "        noisy_logits = logits + noise\n",
        "\n",
        "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices\n",
        "\n",
        "#Now create the sparse mixture of experts module\n",
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def forward(self, x):\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # Reshape inputs for batch processing\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        # Process each expert in parallel\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            # Create a mask for the inputs where the current expert is in top-k\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                expert_output = expert(expert_input)\n",
        "\n",
        "                # Extract and apply gating scores\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                # Update final output\n",
        "                # We need to scatter_add the weighted outputs to their original positions in the batch\n",
        "                final_output.masked_scatter_(expert_mask.unsqueeze(-1), weighted_output)\n",
        "\n",
        "        return final_output.view_as(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bfdff2bb-092f-41c8-9a33-c84e6f8d6633",
          "showTitle": false,
          "title": ""
        },
        "id": "jGiuRsSgkRJk"
      },
      "outputs": [],
      "source": [
        "#First create a self attention + mixture of experts block, that may be repeated several number of times\n",
        "#Copy pasting key architecture variables for clarity\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Mixture of Experts Transformer block: communication followed by computation (multi-head self attention + SparseMoE) \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed, n_head, num_experts, top_k):\n",
        "        # n_embed: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.smoe = SparseMoE(n_embed, num_experts, top_k)\n",
        "        self.ln1 = nn.LayerNorm(n_embed)\n",
        "        self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.smoe(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2d32a276-d0cc-4808-90d7-62441771af44",
          "showTitle": false,
          "title": ""
        },
        "id": "RpyZBA71kRJk"
      },
      "outputs": [],
      "source": [
        "#Finally putting it all together to crease a sparse mixture of experts language model\n",
        "class SparseMoELanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head, num_experts=num_experts,top_k=top_k) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "622ba7ce-3f20-4820-8982-93f3d3b7be09",
          "showTitle": false,
          "title": ""
        },
        "id": "bBzQXmfykRJk"
      },
      "source": [
        "这里使用了Kaiming He初始化，因为专家中存在ReLU激活函数。如果你愿意，可以尝试使用更常用于transformers的Glorot初始化。Jeremy Howard的Fastai第二部分有一节讲座，非常出色地从头开始实现了这些内容：https://course.fast.ai/Lessons/lesson17.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a6d3c057-08ee-4c1b-8013-6a88b2eadac5",
          "showTitle": false,
          "title": ""
        },
        "id": "guGaJqHbkRJk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def kaiming_init_weights(m):\n",
        "    if isinstance (m, (nn.Linear)):\n",
        "        init.kaiming_normal_(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5b4d9525-8405-4a51-adda-661aba004e57",
          "showTitle": false,
          "title": ""
        },
        "id": "nJGGkXz4kRJl",
        "outputId": "8518ec23-caa0-4167-88c6-65a7c905743a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SparseMoELanguageModel(\n",
              "  (token_embedding_table): Embedding(65, 128)\n",
              "  (position_embedding_table): Embedding(32, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SparseMoELanguageModel()\n",
        "model.apply(kaiming_init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6adf1d04-e668-4d14-b691-161ea4e4dccf",
          "showTitle": false,
          "title": ""
        },
        "id": "_cb1-L8ckRJl"
      },
      "source": [
        "我使用mlflow来追踪和记录我关心的指标和训练超参数。下一个单元格中的训练循环包括了这个mlflow代码。如果你希望在不使用mlflow的情况下进行训练，后续单元格中的代码没有mlflow代码。然而，我发现在进行实验时，跟踪参数和指标非常方便。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b8968247-0d7b-4460-b96b-06743b31c55d",
          "showTitle": false,
          "title": ""
        },
        "id": "WTG1Fv4SkRJl",
        "outputId": "38318015-63a9-4959-cfe0-cab305625f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.996545 M parameters\n",
            "step 0: train loss 5.3201, val loss 5.3154\n",
            "step 100: train loss 2.7373, val loss 2.7475\n",
            "step 200: train loss 2.5406, val loss 2.5388\n",
            "step 300: train loss 2.4292, val loss 2.4455\n",
            "step 400: train loss 2.3461, val loss 2.3537\n",
            "step 500: train loss 2.2797, val loss 2.2935\n",
            "step 600: train loss 2.2166, val loss 2.2304\n",
            "step 700: train loss 2.1614, val loss 2.1915\n",
            "step 800: train loss 2.1121, val loss 2.1541\n",
            "step 900: train loss 2.0498, val loss 2.1045\n",
            "step 1000: train loss 2.0205, val loss 2.0841\n",
            "step 1100: train loss 1.9952, val loss 2.0577\n",
            "step 1200: train loss 1.9508, val loss 2.0309\n",
            "step 1300: train loss 1.9423, val loss 2.0409\n",
            "step 1400: train loss 1.9017, val loss 2.0014\n",
            "step 1500: train loss 1.8696, val loss 1.9871\n",
            "step 1600: train loss 1.8472, val loss 1.9692\n",
            "step 1700: train loss 1.8281, val loss 1.9634\n",
            "step 1800: train loss 1.8143, val loss 1.9350\n",
            "step 1900: train loss 1.7997, val loss 1.9247\n",
            "step 2000: train loss 1.7784, val loss 1.9185\n",
            "step 2100: train loss 1.7656, val loss 1.8982\n",
            "step 2200: train loss 1.7548, val loss 1.8907\n",
            "step 2300: train loss 1.7455, val loss 1.8904\n",
            "step 2400: train loss 1.7317, val loss 1.8840\n",
            "step 2500: train loss 1.7242, val loss 1.8804\n",
            "step 2600: train loss 1.7148, val loss 1.8604\n",
            "step 2700: train loss 1.7013, val loss 1.8540\n",
            "step 2800: train loss 1.6908, val loss 1.8594\n",
            "step 2900: train loss 1.6778, val loss 1.8301\n",
            "step 3000: train loss 1.6674, val loss 1.8284\n",
            "step 3100: train loss 1.6746, val loss 1.8243\n",
            "step 3200: train loss 1.6547, val loss 1.8155\n",
            "step 3300: train loss 1.6559, val loss 1.8187\n",
            "step 3400: train loss 1.6379, val loss 1.8050\n",
            "step 3500: train loss 1.6429, val loss 1.8046\n",
            "step 3600: train loss 1.6285, val loss 1.7851\n",
            "step 3700: train loss 1.6292, val loss 1.7910\n",
            "step 3800: train loss 1.6257, val loss 1.7825\n",
            "step 3900: train loss 1.6150, val loss 1.7811\n",
            "step 4000: train loss 1.6120, val loss 1.7743\n",
            "step 4100: train loss 1.6068, val loss 1.7816\n",
            "step 4200: train loss 1.5993, val loss 1.7854\n",
            "step 4300: train loss 1.6018, val loss 1.7766\n",
            "step 4400: train loss 1.5847, val loss 1.7563\n",
            "step 4500: train loss 1.5869, val loss 1.7532\n",
            "step 4600: train loss 1.5758, val loss 1.7572\n",
            "step 4700: train loss 1.5731, val loss 1.7403\n",
            "step 4800: train loss 1.5767, val loss 1.7530\n",
            "step 4900: train loss 1.5728, val loss 1.7394\n",
            "step 4999: train loss 1.5673, val loss 1.7397\n"
          ]
        }
      ],
      "source": [
        "#Using MLFlow\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "#mlflow.set_experiment(\"makeMoE\")\n",
        "with mlflow.start_run():\n",
        "    #If you use mlflow.autolog() this will be automatically logged. I chose to explicitly log here for completeness\n",
        "    params = {\"batch_size\": batch_size , \"block_size\" : block_size, \"max_iters\": max_iters, \"eval_interval\": eval_interval,\n",
        "              \"learning_rate\": learning_rate, \"device\": device, \"eval_iters\": eval_iters, \"dropout\" : dropout, \"num_experts\": num_experts, \"top_k\": top_k }\n",
        "    mlflow.log_params(params)\n",
        "    for iter in range(max_iters):\n",
        "\n",
        "        # every once in a while evaluate the loss on train and val sets\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "            try:\n",
        "                train_loss = float(losses['train'])\n",
        "                val_loss = float(losses['val'])\n",
        "                mlflow.log_metric(\"train_loss\", train_loss, step=int(iter))\n",
        "                mlflow.log_metric(\"val_loss\", val_loss, step=int(iter))\n",
        "            except Exception as e:\n",
        "                print(f\"Error logging metrics at step {iter}: {e}\")\n",
        "                print(f\"Train loss: {losses['train']}, Validation loss: {losses['val']}\")\n",
        "\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1ed96085-c292-4624-a2cc-be8aad38df79",
          "showTitle": false,
          "title": ""
        },
        "id": "jFBVfgfekRJl"
      },
      "source": [
        "记录训练和验证损失可以很好地指示训练进展情况。根据图表显示，我可能应该在大约4500步时停止（当验证损失略微上升时）。\n",
        "\n",
        "![mlflow_dash](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/mlflow_dash.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 可选：不使用MLflow进行训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6360e1b7-94c4-4ef1-a850-9bc93f49a083",
          "showTitle": false,
          "title": ""
        },
        "id": "WP_2lcRUkRJl"
      },
      "outputs": [],
      "source": [
        "#Not using MLflow\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8aa6e4c4-c688-4985-a3b8-e2af1f771e54",
          "showTitle": false,
          "title": ""
        },
        "id": "W4yshpXMkRJl",
        "outputId": "e69af1c7-2e2f-475c-eeba-b20dec8532c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DesparencAtibles them, must\n",
            "To let an ride not them, whole cast be our victery for a mode how;\n",
            "And brother's of mercy atting Her:\n",
            "O, pirate not were me,'r bught, thus.\n",
            "A longergive:n they one lags to both-and slire,\n",
            "The worn brought the came to the har\n",
            "book couls the wour of their\n",
            "or shallinaty house eyes,\n",
            "Which hath state my arch will to give toicit by birmed the burwer.\n",
            "\n",
            "FaLz:\n",
            "This lest in the than mought dostleful dower soul with a recise,\n",
            "If thee your boding made and heer come\n",
            "And his in the four the com shors on flosse.\n",
            "\n",
            "DUCHESS OF 'OF VINESET:\n",
            "Prhate the werbous the world mad!\n",
            "\n",
            "VIRGARY:\n",
            "I come than,\n",
            "We slet's my wifing hour mind eat\n",
            "wick stoment, busting your my of will\n",
            "The did you be?\n",
            "\n",
            "Where IOLA:\n",
            "Ay, by shere and and of satiment know,\n",
            "Ter baniody that jein, chancied this stimpets heart cievervy.\n",
            "Can bedwizader king him commillantate-perch\n",
            "Of their is spink friend our rovening mfore his dame in to tower,\n",
            "And by yether's we; when beind alough's worst it place, thou head, but you bESVY:\n",
            "I will, he lord say an in the hear\n",
            "Wone mon eyery since, and not the maccle?\n",
            "And herein hout tripest to for his in,\n",
            "Tiur pleace 'twas meath shall the sent foem of Hance slionds,\n",
            "Cotius in a wher's puredtice: and 'tis\n",
            "Becappalasedy.\n",
            "\n",
            "First King in Clame:\n",
            "York, good murder lhrike, and were what?\n",
            "\n",
            "Provostn:\n",
            "For My hands lord Yet, when I his glaw by not, a poid.\n",
            "\n",
            "Sennothrow:\n",
            "My obser, and they lear's\n",
            "God promingdy, cholours, bring Ancee you;\n",
            "Sin markst, but for the offerly-ward,\n",
            "Exts wares flowes of Edwarrance,\n",
            "His should, not to by whole itRome.\n",
            "\n",
            "PAULINA:\n",
            "Heve, I well, and think,\n",
            "On loving mone first you which you sweetes nowws your misteryess, the thousags of way,\n",
            "We would you' mear your boy\n",
            "Wears Plays, wake at the\n",
            "ghousace chollant token.\n",
            "\n",
            "GMEO:\n",
            "Which he shad treate, at her all they groue comentes well be couse!\n",
            "\n",
            "RICIONIUS:\n",
            "A! we have fast hit on home in the grief this own; sort expatition a strack-rome which ither and no medir, you will.\n",
            "turn to rear a hear from Lentreat these \n"
          ]
        }
      ],
      "source": [
        "# generate from the model. Not great. Not too bad either\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "makeMoE_from_Scratch",
      "widgets": {}
    },
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "learning-in-general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
